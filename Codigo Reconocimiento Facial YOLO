import os
import cv2
from ultralytics import YOLO

# Ruta al archivo del modelo LBPH (asegúrate de que la ruta sea correcta)
modelo_path = r'D:\\uwu\\diplomado\\proyecto\\Modelos\\modeloLBPHFace.xml'
print("¿Existe el archivo?", os.path.exists(modelo_path))  # Verifica si el archivo del modelo existe

# Ruta a tus datos (asegúrate de que la ruta de 'Data' esté correcta)
dataPath = r'D:\\uwu\\diplomado\\proyecto\\Data'

# Listamos los archivos de la carpeta Data (se supone que ahí están las imágenes de las personas)
imagePaths = os.listdir(dataPath)
print('imagePaths =', imagePaths)

# Cargar el modelo LBPH previamente entrenado
face_recognizer = cv2.face.LBPHFaceRecognizer_create()
face_recognizer.read(r'D:\\uwu\\diplomado\\proyecto\\modeloLBPHFace.xml')  # Cargar el modelo de reconocimiento

# Cargar el modelo YOLO preentrenado para detectar objetos
# El modelo 'yolov8n.pt' es ligero y rápido, puedes usar un modelo más preciso si es necesario
model = YOLO('yolov8n.pt')  # También puedes usar uno especializado en rostros si tienes

# Abrir la cámara o video para realizar la captura en tiempo real
cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)

# Bucle principal para capturar y procesar los frames del video
while True:
    ret, frame = cap.read()  # Captura un frame
    if not ret:  # Si no se puede leer el frame, romper el bucle
        break

    # Realizar la detección de objetos en el frame usando YOLOv8
    results = model(frame)[0]  # Detectar objetos en la imagen

    for result in results.boxes:
        cls = int(result.cls[0])  # Clase del objeto detectado (persona = 0 en YOLOv8)
        conf = float(result.conf[0])  # Confianza de la predicción

        # Solo proceder si la clase detectada es una persona (clase 0) y la confianza es mayor al 50%
        if cls == 0 and conf > 0.5:
            x1, y1, x2, y2 = map(int, result.xyxy[0])  # Coordenadas del rostro detectado
            face = frame[y1:y2, x1:x2]  # Recortar el rostro de la imagen

            # Verificar si el rostro tiene contenido
            if face.size == 0:
                continue  # Si no tiene contenido, saltar al siguiente rostro

            # Convertir la imagen del rostro a escala de grises para el reconocimiento
            face_gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)

            # Redimensionar el rostro a 150x150 píxeles para ajustarse al modelo LBPH
            face_resized = cv2.resize(face_gray, (150, 150), interpolation=cv2.INTER_CUBIC)

            # Realizar la predicción usando el modelo LBPH
            label, confidence = face_recognizer.predict(face_resized)

            # Si la confianza es baja, significa que la persona es reconocida
            if confidence < 70:
                cv2.putText(frame, '{}'.format(imagePaths[label]), (x1, y1 - 10), 1, 1.3, (0, 255, 0), 2)
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Dibujar un cuadro verde alrededor del rostro
            else:
                cv2.putText(frame, 'Desconocido', (x1, y1 - 10), 1, 1.3, (0, 0, 255), 2)
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Dibujar un cuadro rojo alrededor del rostro

    # Mostrar el resultado en una ventana llamada "Reconocimiento Facial YOLO"
    cv2.imshow("Reconocimiento Facial YOLO", frame)

    # Si se presiona la tecla ESC (código 27), salir del bucle
    if cv2.waitKey(1) == 27:  # ESC
        break

# Liberar la cámara y cerrar todas las ventanas de OpenCV
cap.release()
cv2.destroyAllWindows()
